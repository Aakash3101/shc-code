{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cac1a90-cbd7-465d-bc9d-45bcbd441f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/drive%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=sm1P16kBktj9iYLkWUaLNFWJizH6Nz065xfbRIalL-Y&tc=KrTYmhL8rBSf_iYBrF-H4m4Pq_yDCFnmREHZPtsVvEE&cc=ZkH4I6UKR2t2YsdHT4-bkTktcT9IpTeP8bsWRKPSqj8>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/drive%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=sm1P16kBktj9iYLkWUaLNFWJizH6Nz065xfbRIalL-Y&tc=KrTYmhL8rBSf_iYBrF-H4m4Pq_yDCFnmREHZPtsVvEE&cc=ZkH4I6UKR2t2YsdHT4-bkTktcT9IpTeP8bsWRKPSqj8</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AUJR-x7yc7PQIR4CdplkeCTJJfmnl1VYYxK4MTTS2fTvtuxIO33q5bvGCfs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n",
      "Google Earth Engine initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ee.Authenticate()\n",
    "\n",
    "# Initialize Earth Engine\n",
    "try:\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "    print('Google Earth Engine initialized successfully!')\n",
    "except ee.EEException as e:\n",
    "    print('Google Earth Engine failed to initialize!', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f38919-e6ec-4a08-b794-37a854ddda18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MADHYA PRADESH_2024.csv',\n",
       " 'HIMACHAL PRADESH_2024.csv',\n",
       " 'CHHATTISGARH_2024.csv',\n",
       " 'MAHARASHTRA_2024.csv',\n",
       " 'HARYANA_2024.csv',\n",
       " 'ANDHRA PRADESH_2024.csv',\n",
       " 'UTTARAKHAND_2024.csv',\n",
       " 'GUJARAT_2024.csv',\n",
       " 'TELANGANA_2024.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'GOA_2024.csv',\n",
       " 'RAJASTHAN_2024.csv',\n",
       " 'NAGALAND_2024.csv',\n",
       " 'PUNJAB_2024.csv',\n",
       " 'WEST BENGAL_2024.csv',\n",
       " 'ARUNACHAL PRADESH_2024.csv',\n",
       " 'TRIPURA_2024.csv',\n",
       " 'BIHAR_2024.csv',\n",
       " 'ODISHA_2024.csv',\n",
       " 'KARNATAKA_2024.csv',\n",
       " 'JAMMU & KASHMIR_2024.csv',\n",
       " 'ANDAMAN & NICOBAR_2024.csv',\n",
       " 'JHARKHAND_2024.csv',\n",
       " 'MEGHALAYA_2024.csv',\n",
       " 'UTTAR PRADESH_2024.csv',\n",
       " 'PUDUCHERRY_2024.csv',\n",
       " 'SIKKIM_2024.csv',\n",
       " 'MIZORAM_2024.csv',\n",
       " 'LADAKH_2024.csv',\n",
       " 'ASSAM_2024.csv',\n",
       " 'TAMIL NADU_2024.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./shc_data/NORMALISED_DATA/2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63681f22-d3cf-4978-afd0-94f5917e78d0",
   "metadata": {},
   "source": [
    "0: \n",
    "Andaman & Nicobar\n",
    "1: \n",
    "Andhra Pradesh\n",
    "2: \n",
    "Arunachal Pradesh\n",
    "3: \n",
    "Assam\n",
    "4: \n",
    "Bihar\n",
    "5: \n",
    "Chandigarh\n",
    "6: \n",
    "Chhattishgarh\n",
    "7: \n",
    "Daman and Diu and Dadra and Nagar Haveli\n",
    "8: \n",
    "Delhi\n",
    "9: \n",
    "Goa\n",
    "10: \n",
    "Gujarat\n",
    "11: \n",
    "Haryana\n",
    "12: \n",
    "Himachal Pradesh\n",
    "13: \n",
    "Jammu and Kashmir\n",
    "14: \n",
    "Jharkhand\n",
    "15: \n",
    "Karnataka\n",
    "16: \n",
    "Kerala\n",
    "17: \n",
    "Ladakh\n",
    "18: \n",
    "Lakshadweep\n",
    "19: \n",
    "Madhya Pradesh\n",
    "20: \n",
    "Maharashtra\n",
    "21: \n",
    "Manipur\n",
    "22: \n",
    "Meghalaya\n",
    "23: \n",
    "Mizoram\n",
    "24: \n",
    "Nagaland\n",
    "25: \n",
    "Odisha\n",
    "26: \n",
    "Puducherry\n",
    "27: \n",
    "Puducherry\n",
    "28: \n",
    "Punjab\n",
    "29: \n",
    "Rajasthan\n",
    "30: \n",
    "Sikkim\n",
    "31: \n",
    "Tamilnadu\n",
    "32: \n",
    "Telengana\n",
    "33: \n",
    "Tripura\n",
    "34: \n",
    "Uttar Pradesh\n",
    "35: \n",
    "Uttarakhand\n",
    "36: \n",
    "West Bengal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da6dbe2a-3c66-4047-b175-a9e1899ec8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === CONFIGURABLE PARAMETERS ===\n",
    "INPUT_CSV = \"../data/filtered_2023-24/ASSAM_2023_24.csv\"  # CSV containing soil properties\n",
    "OUTPUT_FOLDER = \"./experiments/LA_23_24\"  # Folder to save results\n",
    "BATCH_SIZE = 1000  # Number of points processed per batch\n",
    "\n",
    "india_districts = ee.FeatureCollection(\"projects/ee-aakash312000/assets/state\")\n",
    "state = india_districts.filter(ee.Filter.eq('State_Name', 'Assam'))\n",
    "\n",
    "# Create output folder if not exists\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "collections = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e943095-3cd8-4630-a946-ebf5f0194c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import geemap\n",
    "import datetime\n",
    "\n",
    "def renameBands(image):\n",
    "    return image.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7'], ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "\n",
    "def maskL8clouds(image):\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    cloudMask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "    shadowMask = qa.bitwiseAnd(1 << 3).eq(0)\n",
    "    mask = cloudMask.And(shadowMask)\n",
    "    scaled = image.multiply(0.0000275).add(-0.2)\n",
    "    bands = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']\n",
    "    return scaled.updateMask(mask).select(bands, ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']).toFloat()\n",
    "\n",
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60');\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10;\n",
    "    cirrusBitMask = 1 << 11;\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "    scaled = image.divide(10000)\n",
    "    scaled = scaled.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'], ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "    return scaled.updateMask(mask).toFloat()\n",
    "\n",
    "# Apply harmonization for Sentinel-2\n",
    "slopes = [1.0946, 1.0043, 1.0524, 0.8954, 1.0049, 1.0002]\n",
    "intercepts = [-0.0107, 0.0026, -0.0015, 0.0033, 0.0065, 0.0046]\n",
    "\n",
    "def convert(image):\n",
    "  return image.select(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']).multiply(slopes).add(intercepts)\n",
    "\n",
    "# date_range_month = {\n",
    "#     \"Jan\" : (ee.Date(\"2023-01-01\"), ee.Date(\"2023-01-31\")),\n",
    "#     \"Feb\" : (ee.Date(\"2023-02-01\"), ee.Date(\"2023-02-28\")),\n",
    "#     \"Mar\" : (ee.Date(\"2023-03-01\"), ee.Date(\"2023-03-31\")),\n",
    "#     \"Apr\" : (ee.Date(\"2023-04-01\"), ee.Date(\"2023-04-30\")),\n",
    "#     \"May\" : (ee.Date(\"2023-05-01\"), ee.Date(\"2023-05-31\")),\n",
    "#     \"Jun\" : (ee.Date(\"2023-06-01\"), ee.Date(\"2023-06-30\")),\n",
    "#     \"Jul\" : (ee.Date(\"2023-07-01\"), ee.Date(\"2023-07-31\")),\n",
    "#     \"Aug\" : (ee.Date(\"2023-08-01\"), ee.Date(\"2023-08-31\")),\n",
    "#     \"Sep\" : (ee.Date(\"2023-09-01\"), ee.Date(\"2023-09-30\")),\n",
    "#     \"Oct\" : (ee.Date(\"2023-10-01\"), ee.Date(\"2023-10-31\")),\n",
    "#     \"Nov\" : (ee.Date(\"2023-11-01\"), ee.Date(\"2023-11-30\")),\n",
    "#     \"Dec\" : (ee.Date(\"2023-12-01\"), ee.Date(\"2023-12-31\"))\n",
    "# }\n",
    "\n",
    "def harmonize_collections(start_date, end_date, roi, month):\n",
    "    \"\"\"Fetches harmonized Sentinel-2 and Landsat collections with indices.\"\"\"\n",
    "\n",
    "    def update(image):\n",
    "      return image.multiply(0.002)\n",
    "\n",
    "    S2 = (\n",
    "        ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "        .filterBounds(roi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 40))\n",
    "        .map(maskS2clouds)\n",
    "    )\n",
    "    \n",
    "    temp = (\n",
    "            ee.ImageCollection(\"MODIS/061/MOD11A2\")\n",
    "            .select('LST_Day_1km')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterBounds(roi)\n",
    "            .map(lambda img: update(img))\n",
    "            .mean()\n",
    "            .rename('temp')\n",
    "    )\n",
    "    \n",
    "    preci = (\n",
    "            ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterBounds(roi)\n",
    "            .mean()\n",
    "            .rename('precipitation')      \n",
    "    )\n",
    "\n",
    "    elevation = ee.Image(\"USGS/SRTMGL1_003\").select(\"elevation\").clip(roi)\n",
    "    slope = ee.Terrain.slope(elevation).rename('slope')\n",
    "    aspect = ee.Terrain.aspect(elevation).rename('aspect')\n",
    "    \n",
    "    slope_radians = slope.multiply(math.pi).divide(180)\n",
    "    \n",
    "    flow_accumulation = ee.Image(\"MERIT/Hydro/v1_0_1\").select(\"upa\").clip(roi) # Upstream Area (Flow Accumulation)\n",
    "    \n",
    "    tan_slope = slope_radians.tan()\n",
    "    safe_slope = tan_slope.where(tan_slope.eq(0), 0.001)\n",
    "    \n",
    "    twi = flow_accumulation.divide(safe_slope).log().rename('TWI')\n",
    "\n",
    "    sand = ee.Image(\"projects/soilgrids-isric/sand_mean\").select([\"sand_0-5cm_mean\", \"sand_5-15cm_mean\"]).clip(roi).rename(['sand05', 'sand515']);\n",
    "    silt = ee.Image(\"projects/soilgrids-isric/silt_mean\").select([\"silt_0-5cm_mean\", \"silt_5-15cm_mean\"]).clip(roi).rename(['silt05', 'silt515']);\n",
    "    clay = ee.Image(\"projects/soilgrids-isric/clay_mean\").select([\"clay_0-5cm_mean\", \"clay_5-15cm_mean\"]).clip(roi).rename(['clay05', 'clay515']);\n",
    "\n",
    "    S2 = S2.map(lambda img: img.toFloat())\n",
    "    s2 = S2.mean()\n",
    "\n",
    "    monthly_stack = s2.addBands(temp).addBands(preci)\n",
    "    if month is not None:\n",
    "        month_prefix = ee.String(month.lower() + \"_\")\n",
    "        renamed_bands = monthly_stack.bandNames().map(lambda b: month_prefix.cat(ee.String(b)))\n",
    "        monthly_stack = monthly_stack.rename(renamed_bands)\n",
    "    collection = ee.Image([monthly_stack, elevation, slope, aspect, twi, sand, clay, silt])\n",
    "    \n",
    "    return collection\n",
    "\n",
    "def fetch_indices_for_district(df, district, month, start_date, end_date):\n",
    "    global collections\n",
    "    \"\"\"Processes a district's data in batches and fetches satellite indices.\"\"\"\n",
    "    \n",
    "    # Filter district data\n",
    "    district_df = df[df[\"district\"] == district].reset_index(drop=True)\n",
    "    total_features = len(district_df)\n",
    "    \n",
    "    processed = 0\n",
    "    batch_number = 1\n",
    "    start_time = time.time()\n",
    "    all_results = []\n",
    "\n",
    "    while processed < total_features:\n",
    "        batch_df = district_df.iloc[processed : processed + BATCH_SIZE]\n",
    "        points = ee.FeatureCollection([\n",
    "            ee.Feature(ee.Geometry.Point(row['long'], row['lat']), {\n",
    "                'district' : row['district'],\n",
    "                'village' : row['village'],\n",
    "                'date': row['date'],\n",
    "                'start_date': row['start_date'],\n",
    "                'end_date': row['end_date'],\n",
    "                'N': row['N'],\n",
    "                'P': row['P'],\n",
    "                'K': row['K'],\n",
    "                'B': row['B'],\n",
    "                'Fe': row['Fe'],\n",
    "                'Zn': row['Zn'],\n",
    "                'Cu': row['Cu'],\n",
    "                'S': row['S'],\n",
    "                'OC': row['OC'],\n",
    "                'pH': row['pH'],\n",
    "                'Mn': row['Mn'],\n",
    "                'EC': row['EC']\n",
    "            })\n",
    "            for _, row in batch_df.iterrows()\n",
    "        ])\n",
    "\n",
    "\n",
    "        points = points.filterBounds(state.geometry())\n",
    "        roi = points.geometry().bounds()\n",
    "        collections = harmonize_collections(start_date, end_date, roi, month)\n",
    "        sampled_points = collections.sampleRegions(\n",
    "            collection=points, scale=30, tileScale=8, geometries=True\n",
    "        )\n",
    "\n",
    "        state_name = INPUT_CSV.split(\"/\")[-1].split(\".csv\")[0]\n",
    "\n",
    "        task = ee.batch.Export.table.toDrive(\n",
    "            collection=sampled_points,\n",
    "            description=f\"{state_name}_sampled_batch_{batch_number}\",\n",
    "            folder='GEE_Exports',\n",
    "            fileNamePrefix=f\"{state_name}_{district}_batch{batch_number}\",\n",
    "            fileFormat='CSV'\n",
    "        )\n",
    "        task.start()\n",
    "\n",
    "        processed += BATCH_SIZE\n",
    "        batch_number += 1\n",
    "        print(f\"Batch {batch_number-1} processed. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65879d66-d019-4251-a7a2-1c04f305ce4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    global collections\n",
    "    \"\"\"Main function to process all districts.\"\"\"\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    \n",
    "    # Ensure necessary columns exist\n",
    "    required_columns = {\"long\", \"lat\", \"district\", \"village\", \"date\"}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        raise ValueError(f\"CSV file must contain columns: {required_columns}\")\n",
    "\n",
    "    # Process districts\n",
    "    unique_districts = df[\"district\"].unique()\n",
    "    print(f\"Total Districts: {len(unique_districts)}\")\n",
    "\n",
    "    start_date, end_date = ee.Date(\"2024-01-01\"), ee.Date(\"2024-12-31\")\n",
    "    \n",
    "    for district in unique_districts:\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        print(f\"\\nProcessing District: {district}\")\n",
    "        batch_df = df[df[\"district\"] == district].reset_index(drop=True)\n",
    "        total_features = len(batch_df)\n",
    "        print(f\"Total Features in {district}: {total_features}\")\n",
    "\n",
    "        # Annual mean data downloading\n",
    "        if os.path.exists(os.path.join(OUTPUT_FOLDER, f\"{district}_indices.csv\")):\n",
    "            print(f\"Features already extracted for {district} \")\n",
    "            continue\n",
    "            \n",
    "        fetch_indices_for_district(df, district, None, start_date, end_date)\n",
    "        \n",
    "        # Month wise data donwloading \n",
    "        # for month in date_range_month.keys():\n",
    "        #     if os.path.exists(os.path.join(OUTPUT_FOLDER, f\"{district}_{month.upper()}_indices.csv\")):\n",
    "        #         print(f\"Features already extracted for {district} for month {month.upper()}\")\n",
    "        #         continue\n",
    "        #     print(f\"\\nFetching data for month : {month.upper()}\")\n",
    "            \n",
    "        #     start_date, end_date = date_range_month[month]\n",
    "        #     fetch_indices_for_district(df, district, month, start_date, end_date)\n",
    "            \n",
    "        end_time = time.perf_counter()\n",
    "        elapsed_time = end_time - start_time\n",
    "        a = datetime.timedelta(seconds=elapsed_time)\n",
    "        print(\"Time taken : \" + str(a))\n",
    "        \n",
    "\n",
    "    print(\"\\nAll districts processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8f36fec-f35e-4375-a9f7-0afc88d093da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Districts: 17\n",
      "\n",
      "Processing District: BAKSA\n",
      "Total Features in BAKSA: 4451\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Batch 4 processed. \n",
      "Batch 5 processed. \n",
      "Time taken : 0:00:25.566644\n",
      "\n",
      "Processing District: BARPETA\n",
      "Total Features in BARPETA: 53722\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Batch 4 processed. \n",
      "Batch 5 processed. \n",
      "Batch 6 processed. \n",
      "Batch 7 processed. \n",
      "Batch 8 processed. \n",
      "Batch 9 processed. \n",
      "Batch 10 processed. \n",
      "Batch 11 processed. \n",
      "Batch 12 processed. \n",
      "Batch 13 processed. \n",
      "Batch 14 processed. \n",
      "Batch 15 processed. \n",
      "Batch 16 processed. \n",
      "Batch 17 processed. \n",
      "Batch 18 processed. \n",
      "Batch 19 processed. \n",
      "Batch 20 processed. \n",
      "Batch 21 processed. \n",
      "Batch 22 processed. \n",
      "Batch 23 processed. \n",
      "Batch 24 processed. \n",
      "Batch 25 processed. \n",
      "Batch 26 processed. \n",
      "Batch 27 processed. \n",
      "Batch 28 processed. \n",
      "Batch 29 processed. \n",
      "Batch 30 processed. \n",
      "Batch 31 processed. \n",
      "Batch 32 processed. \n",
      "Batch 33 processed. \n",
      "Batch 34 processed. \n",
      "Batch 35 processed. \n",
      "Batch 36 processed. \n",
      "Batch 37 processed. \n",
      "Batch 38 processed. \n",
      "Batch 39 processed. \n",
      "Batch 40 processed. \n",
      "Batch 41 processed. \n",
      "Batch 42 processed. \n",
      "Batch 43 processed. \n",
      "Batch 44 processed. \n",
      "Batch 45 processed. \n",
      "Batch 46 processed. \n",
      "Batch 47 processed. \n",
      "Batch 48 processed. \n",
      "Batch 49 processed. \n",
      "Batch 50 processed. \n",
      "Batch 51 processed. \n",
      "Batch 52 processed. \n",
      "Batch 53 processed. \n",
      "Batch 54 processed. \n",
      "Time taken : 0:04:57.351695\n",
      "\n",
      "Processing District: CACHAR\n",
      "Total Features in CACHAR: 119\n",
      "Batch 1 processed. \n",
      "Time taken : 0:00:01.779946\n",
      "\n",
      "Processing District: DARRANG\n",
      "Total Features in DARRANG: 582\n",
      "Batch 1 processed. \n",
      "Time taken : 0:00:03.209270\n",
      "\n",
      "Processing District: DHEMAJI\n",
      "Total Features in DHEMAJI: 616\n",
      "Batch 1 processed. \n",
      "Time taken : 0:00:03.339062\n",
      "\n",
      "Processing District: DHUBRI\n",
      "Total Features in DHUBRI: 17994\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Batch 4 processed. \n",
      "Batch 5 processed. \n",
      "Batch 6 processed. \n",
      "Batch 7 processed. \n",
      "Batch 8 processed. \n",
      "Batch 9 processed. \n",
      "Batch 10 processed. \n",
      "Batch 11 processed. \n",
      "Batch 12 processed. \n",
      "Batch 13 processed. \n",
      "Batch 14 processed. \n",
      "Batch 15 processed. \n",
      "Batch 16 processed. \n",
      "Batch 17 processed. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991ec5f-7d6c-4271-869e-0e9259f0af9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967cf616-ff2d-4564-b7ea-785a8b664f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
