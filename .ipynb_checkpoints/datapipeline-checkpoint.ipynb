{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cac1a90-cbd7-465d-bc9d-45bcbd441f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Earth Engine initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ee.Authenticate()\n",
    "\n",
    "# Initialize Earth Engine\n",
    "try:\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "    print('Google Earth Engine initialized successfully!')\n",
    "except ee.EEException as e:\n",
    "    print('Google Earth Engine failed to initialize!', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ff800-a4c0-437b-b456-2e65a2bb6e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "# from shapely.geometry import Point\n",
    "# import os\n",
    "# import glob\n",
    "\n",
    "# # Load AEZ GeoJSON file\n",
    "# aez_gdf = gpd.read_file(\"../WRIS/Agro Ecological Regions.geojson\")\n",
    "\n",
    "# # Ensure AEZ data is in the correct coordinate reference system (CRS)\n",
    "# aez_gdf = aez_gdf.to_crs(epsg=4326)  # Convert to WGS84 if not already\n",
    "\n",
    "# def segregate_by_aez(district_df):\n",
    "#     # Convert to GeoDataFrame\n",
    "#     district_gdf = gpd.GeoDataFrame(\n",
    "#         district_df, \n",
    "#         geometry=[Point(xy) for xy in zip(district_df[\"longitude\"], district_df[\"latitude\"])],\n",
    "#         crs=\"EPSG:4326\"\n",
    "#     )\n",
    "    \n",
    "#     # Spatial join: Find which AEZ each point belongs to\n",
    "#     joined_gdf = gpd.sjoin(district_gdf, aez_gdf, how=\"left\", predicate=\"within\")\n",
    "#     # Keep only relevant columns\n",
    "#     result_df = joined_gdf.drop(columns=[\"geometry\", \"index_right\", 'GmlID', 'objectid', 'physio_reg', 'area_sqkm', 'st_area_shape_', 'st_length_shape_'])  # Drop extra columns\n",
    "#     # result_df.to_csv(\"AEZ_marked_data.csv\", index=False)\n",
    "    \n",
    "#     return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f38919-e6ec-4a08-b794-37a854ddda18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AEZ_18.csv',\n",
       " 'AEZ_11.csv',\n",
       " 'AEZ_14.csv',\n",
       " 'AEZ_10.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'AEZ_8.csv',\n",
       " 'AEZ_17.csv',\n",
       " 'AEZ_19.csv',\n",
       " 'AEZ_16.csv',\n",
       " 'AEZ_12.csv',\n",
       " 'AEZ_5.csv',\n",
       " 'AEZ_3.csv',\n",
       " 'AEZ_6.csv',\n",
       " 'AEZ_20.csv',\n",
       " 'AEZ_4.csv',\n",
       " 'AEZ_15.csv',\n",
       " 'AEZ_9.csv',\n",
       " 'AEZ_13.csv',\n",
       " 'AEZ_2.csv',\n",
       " 'AEZ_7.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./new_data/AEZs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9940b6f4-0c7a-4342-824d-b872fc7d2035",
   "metadata": {},
   "source": [
    " <!-- 'PUNJAB_2023_24.csv', -->\n",
    " <!-- 'LADAKH_2023_24.csv', -->\n",
    " <!-- 'HARYANA_2023_24.csv', -->\n",
    " <!-- 'MIZORAM_2023_24.csv', -->\n",
    " <!-- 'CHHATTISGARH_2023_24.csv', -->\n",
    " <!-- 'ASSAM_2023_24.csv', -->\n",
    " <!-- 'TRIPURA_2023_24.csv', -->\n",
    " <!-- 'UTTAR_PRADESH_2023_24.csv', -->\n",
    " <!-- 'ANDAMAN_&_NICOBAR_2023_24.csv', -->\n",
    " <!-- 'RAJASTHAN_2023_24.csv', -->\n",
    " <!-- 'ANDHRA_PRADESH_2023_24.csv', -->\n",
    " <!-- 'GUJARAT_2023_24.csv', -->\n",
    " <!-- 'ODISHA_2023_24.csv', -->\n",
    " <!-- 'MAHARASHTRA_2023_24.csv', -->\n",
    " <!-- 'PUDUCHERRY_2023_24.csv', -->\n",
    " <!-- 'MEGHALAYA_2023_24.csv', -->\n",
    " <!-- 'JAMMU_&_KASHMIR_2023_24.csv', -->\n",
    " <!-- 'MADHYA_PRADESH_2023_24.csv', -->\n",
    " <!-- 'NAGALAND_2023_24.csv', -->\n",
    " <!-- 'WEST_BENGAL_2023_24.csv', -->\n",
    " <!-- 'UTTARAKHAND_2023_24.csv', -->\n",
    " <!-- 'GOA_2023_24.csv', -->\n",
    " <!-- 'BIHAR_2023_24.csv', -->\n",
    " <!-- 'TAMIL_NADU_2023_24.csv', -->\n",
    " <!-- 'KARNATAKA_2023_24.csv', -->\n",
    " <!-- 'ARUNACHAL_PRADESH_2023_24.csv', -->\n",
    " <!-- 'HIMACHAL_PRADESH_2023_24.csv', -->\n",
    " <!-- 'JHARKHAND_2023_24.csv' -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6dbe2a-3c66-4047-b175-a9e1899ec8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURABLE PARAMETERS ===\n",
    "AEZ = 5\n",
    "INPUT_CSV = f\"./new_data/AEZs/AEZ_{AEZ}.csv\"  # CSV containing soil properties\n",
    "OUTPUT_FOLDER = \"./new_data/processed\"  # Folder to save results\n",
    "BATCH_SIZE = 1000  # Number of points processed per batch\n",
    "\n",
    "# india_districts = ee.FeatureCollection(\"projects/ee-aakash312000/assets/state\")\n",
    "# state = india_districts.filter(ee.Filter.eq('State_Name', 'Ladakh'))\n",
    "\n",
    "aez_fc = ee.FeatureCollection(\"projects/ee-aakash312000/assets/Agro_Ecological_Regions\")\n",
    "current_aez = aez_fc.filter(ee.Filter.eq('ae_regcode', AEZ))\n",
    "\n",
    "# Create output folder if not exists\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "collections = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a429dcda-3a31-47eb-abc9-22051e06097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cloud masking functions\n",
    "# def mask_l8_cloud(image):\n",
    "#     qa = image.select('QA_PIXEL')\n",
    "#     cloud_mask = qa.bitwiseAnd(1 << 4).eq(0).And(qa.bitwiseAnd(1 << 5).eq(0))\n",
    "#     return image.updateMask(cloud_mask).select(\n",
    "#         ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "#     ).rename(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "\n",
    "# def mask_l7_cloud(image):\n",
    "#     qa = image.select('QA_PIXEL')\n",
    "#     cloud_mask = qa.bitwiseAnd(1 << 4).eq(0).And(qa.bitwiseAnd(1 << 5).eq(0))\n",
    "#     return image.updateMask(cloud_mask).select(\n",
    "#         ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']\n",
    "#     ).rename(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "\n",
    "# def mask_s2_cloud(image):\n",
    "#     cloud_prob = image.select('MSK_CLDPRB')\n",
    "#     mask = cloud_prob.lt(20)  # Cloud probability < 20%\n",
    "#     return image.select(\n",
    "#         ['B2', 'B3', 'B4', 'B8', 'B11', 'B12']\n",
    "#     ).rename(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']).updateMask(mask)\n",
    "\n",
    "# # Harmonization function\n",
    "# def harmonization_chastain(img, from_sensor, to_sensor):\n",
    "#     chastain_band_names = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']\n",
    "#     chastain_coeff_dict = {\n",
    "#     'MSI_OLI': [[1.0946,1.0043,1.0524,0.8954,1.0049,1.0002], [-0.0107,0.0026,-0.0015,0.0033,0.0065,0.0046], 1],\n",
    "#     'MSI_ETM': [[1.10601,0.99091,1.05681,1.0045,1.03611,1.04011], [-0.0139,0.00411,-0.0024,-0.0076,0.00411,0.00861], 1],\n",
    "#     'OLI_ETM': [[1.03501,1.00921,1.01991,1.14061,1.04351,1.05271], [-0.0055,-0.0008,-0.0021,-0.0163,-0.0045,0.00261], 1],\n",
    "#     'OLI_MSI': [[1.0946,1.0043,1.0524,0.8954,1.0049,1.0002], [-0.0107,0.0026,-0.0015,0.0033,0.0065,0.0046], 0],\n",
    "#     'ETM_MSI': [[1.10601,0.99091,1.05681,1.0045,1.03611,1.04011], [-0.0139,0.00411,-0.0024,-0.0076,0.00411,0.00861], 0],\n",
    "#     'ETM_OLI': [[1.03501,1.00921,1.01991,1.14061,1.04351,1.05271], [-0.0055,-0.0008,-0.0021,-0.0163,-0.0045,0.00261], 0]\n",
    "#     }\n",
    "\n",
    "#     combo_key = f'{from_sensor}_{to_sensor}'.upper()\n",
    "#     coeff_list = chastain_coeff_dict[combo_key]\n",
    "#     slopes, intercepts, direction = coeff_list[0], coeff_list[1], coeff_list[2]\n",
    "\n",
    "#     if direction == 0:\n",
    "#         return img.select(chastain_band_names).multiply(slopes).add(intercepts)\n",
    "#     else:\n",
    "#         return img.select(chastain_band_names).subtract(intercepts).divide(slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c3bdfe-3121-411e-a095-a20dd405b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Vegetation Indices (NDVI, EVI, SAVI, NDWI)\n",
    "def add_indices(image):\n",
    "    ndvi = image.normalizedDifference(['NIR', 'RED']).rename('NDVI')\n",
    "    \n",
    "    evi = image.expression(\n",
    "        '2.5 * (NIR - RED) / (NIR + 6*RED - 7.5*BLUE + 1)',\n",
    "        {\n",
    "          'NIR': image.select('NIR'),\n",
    "          'RED': image.select('RED'),\n",
    "          'BLUE': image.select('BLUE')\n",
    "        }).rename('EVI')\n",
    "    \n",
    "    ndwi = image.normalizedDifference(['GREEN', 'NIR']).rename('NDWI') \n",
    "    \n",
    "    savi = image.expression(\n",
    "        '(NIR - RED) / (NIR + RED + 0.5) * (1.5)',\n",
    "        {\n",
    "          'NIR': image.select('NIR'),\n",
    "          'RED': image.select('RED')\n",
    "        }).rename('SAVI')\n",
    "    \n",
    "    bi = image.expression(\n",
    "        'sqrt((RED**2 + GREEN**2 + BLUE**2) / 3)', {\n",
    "          'RED': image.select('RED'),   # Red band\n",
    "          'GREEN': image.select('GREEN'), # Green band\n",
    "          'BLUE': image.select('BLUE')   # Blue band\n",
    "        }).rename('BI')\n",
    "    \n",
    "    si = image.normalizedDifference(['RED', 'BLUE']).rename('SI')\n",
    "    \n",
    "    hi = image.expression('(2*RED - GREEN - BLUE) / (GREEN - BLUE)', {\n",
    "        'RED': image.select('RED'),   # Red band\n",
    "        'GREEN': image.select('GREEN'), # Green band\n",
    "        'BLUE': image.select('BLUE')   # Blue band\n",
    "        }).rename('HI')\n",
    "    \n",
    "    ci = image.normalizedDifference(['RED', 'GREEN']).rename('CI')\n",
    "    \n",
    "    ri = image.expression('RED**2 / (BLUE * GREEN**3)', {\n",
    "        'RED': image.select('RED'),   # Red band\n",
    "        'GREEN': image.select('GREEN'), # Green band\n",
    "        'BLUE': image.select('BLUE')   # Blue band\n",
    "        }).rename('RI')\n",
    "    \n",
    "    tgsi = image.normalizedDifference(['SWIR1', 'NIR']).rename('TGSI')\n",
    "    nci = image.normalizedDifference(['SWIR1', 'SWIR2']).rename('NCI')\n",
    "    gndvi = image.normalizedDifference(['NIR', 'GREEN']).rename('GNDVI')\n",
    "\n",
    "    return image.addBands([ndvi, evi, ndwi, savi, bi, si, hi, ci, ri, tgsi, nci, gndvi]).toFloat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e943095-3cd8-4630-a946-ebf5f0194c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import geemap\n",
    "import datetime\n",
    "\n",
    "def renameBands(image):\n",
    "    return image.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7'], ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "\n",
    "def maskL8clouds(image):\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    cloudMask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "    shadowMask = qa.bitwiseAnd(1 << 3).eq(0)\n",
    "    mask = cloudMask.And(shadowMask)\n",
    "    scaled = image.multiply(0.0000275).add(-0.2)\n",
    "    bands = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']\n",
    "    return scaled.updateMask(mask).select(bands, ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']).toFloat()\n",
    "\n",
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60');\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10;\n",
    "    cirrusBitMask = 1 << 11;\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "    scaled = image.divide(10000)\n",
    "    scaled = scaled.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'], ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "    return scaled.updateMask(mask).toFloat()\n",
    "\n",
    "# Apply harmonization for Sentinel-2\n",
    "slopes = [1.0946, 1.0043, 1.0524, 0.8954, 1.0049, 1.0002]\n",
    "intercepts = [-0.0107, 0.0026, -0.0015, 0.0033, 0.0065, 0.0046]\n",
    "\n",
    "def convert(image):\n",
    "  return image.select(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']).multiply(slopes).add(intercepts)\n",
    "\n",
    "date_range_month = {\n",
    "    \"Jan\" : (ee.Date(\"2023-01-01\"), ee.Date(\"2023-01-31\")),\n",
    "    \"Feb\" : (ee.Date(\"2023-02-01\"), ee.Date(\"2023-02-28\")),\n",
    "    \"Mar\" : (ee.Date(\"2023-03-01\"), ee.Date(\"2023-03-31\")),\n",
    "    \"Apr\" : (ee.Date(\"2023-04-01\"), ee.Date(\"2023-04-30\")),\n",
    "    \"May\" : (ee.Date(\"2023-05-01\"), ee.Date(\"2023-05-31\")),\n",
    "    \"Jun\" : (ee.Date(\"2023-06-01\"), ee.Date(\"2023-06-30\")),\n",
    "    \"Jul\" : (ee.Date(\"2023-07-01\"), ee.Date(\"2023-07-31\")),\n",
    "    \"Aug\" : (ee.Date(\"2023-08-01\"), ee.Date(\"2023-08-31\")),\n",
    "    \"Sep\" : (ee.Date(\"2023-09-01\"), ee.Date(\"2023-09-30\")),\n",
    "    \"Oct\" : (ee.Date(\"2023-10-01\"), ee.Date(\"2023-10-31\")),\n",
    "    \"Nov\" : (ee.Date(\"2023-11-01\"), ee.Date(\"2023-11-30\")),\n",
    "    \"Dec\" : (ee.Date(\"2023-12-01\"), ee.Date(\"2023-12-31\"))\n",
    "}\n",
    "\n",
    "def harmonize_collections(start_date, end_date, roi, month):\n",
    "    \"\"\"Fetches harmonized Sentinel-2 and Landsat collections with indices.\"\"\"\n",
    "    # L8 = (\n",
    "    #     ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
    "    #     .filterBounds(roi)\n",
    "    #     .filterDate(start_date, end_date)\n",
    "    #     .map(mask_l8_cloud)\n",
    "    #     # .map(add_indices)\n",
    "    # )\n",
    "\n",
    "    # L7 = (\n",
    "    #     ee.ImageCollection('LANDSAT/LE07/C02/T1_L2')\n",
    "    #     .filterBounds(roi)\n",
    "    #     .filterDate(start_date, end_date)\n",
    "    #     .map(mask_l7_cloud)\n",
    "    #     .map(lambda img: harmonization_chastain(img, 'ETM', 'OLI'))\n",
    "    #     # .map(add_indices)\n",
    "    # )\n",
    "\n",
    "    # S2 = (\n",
    "    #     ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "    #     .filterBounds(roi)\n",
    "    #     .filterDate(start_date, end_date)\n",
    "    #     .map(mask_s2_cloud)\n",
    "    #     .map(lambda img: harmonization_chastain(img, 'MSI', 'OLI'))\n",
    "    #     # .map(add_indices)\n",
    "    # )\n",
    "\n",
    "    def update(image):\n",
    "      return image.multiply(0.002)\n",
    "\n",
    "    # L8 = (\n",
    "    #     ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
    "    #     .filterBounds(roi)\n",
    "    #     .filterDate(start_date, end_date)\n",
    "    #     .filter(ee.Filter.lt('CLOUD_COVER', 20))\n",
    "    #     .map(maskL8clouds)\n",
    "    # )\n",
    "\n",
    "    S2 = (\n",
    "        ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "        .filterBounds(roi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 40))\n",
    "        .map(maskS2clouds)\n",
    "    )\n",
    "    \n",
    "    temp = (\n",
    "            ee.ImageCollection(\"MODIS/061/MOD11A2\")\n",
    "            .select('LST_Day_1km')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterBounds(roi)\n",
    "            .map(lambda img: update(img))\n",
    "            .mean()\n",
    "            .rename('temp')\n",
    "    )\n",
    "    \n",
    "    preci = (\n",
    "            ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterBounds(roi)\n",
    "            .mean()\n",
    "            .rename('precipitation')      \n",
    "    )\n",
    "\n",
    "    elevation = ee.Image(\"USGS/SRTMGL1_003\").select(\"elevation\").clip(roi)\n",
    "    slope = ee.Terrain.slope(elevation).rename('slope')\n",
    "    aspect = ee.Terrain.aspect(elevation).rename('aspect')\n",
    "    \n",
    "    slope_radians = slope.multiply(math.pi).divide(180)\n",
    "    \n",
    "    flow_accumulation = ee.Image(\"MERIT/Hydro/v1_0_1\").select(\"upa\").clip(roi) # Upstream Area (Flow Accumulation)\n",
    "    \n",
    "    tan_slope = slope_radians.tan()\n",
    "    safe_slope = tan_slope.where(tan_slope.eq(0), 0.001)\n",
    "    \n",
    "    twi = flow_accumulation.divide(safe_slope).log().rename('TWI')\n",
    "\n",
    "    sand = ee.Image(\"projects/soilgrids-isric/sand_mean\").select([\"sand_0-5cm_mean\", \"sand_5-15cm_mean\"]).clip(roi).rename(['sand05', 'sand515']);\n",
    "    silt = ee.Image(\"projects/soilgrids-isric/silt_mean\").select([\"silt_0-5cm_mean\", \"silt_5-15cm_mean\"]).clip(roi).rename(['silt05', 'silt515']);\n",
    "    clay = ee.Image(\"projects/soilgrids-isric/clay_mean\").select([\"clay_0-5cm_mean\", \"clay_5-15cm_mean\"]).clip(roi).rename(['clay05', 'clay515']);\n",
    "\n",
    "    # L8 = L8.map(convert)\n",
    "    # L8 = L8.map(lambda img: img.toFloat())\n",
    "    S2 = S2.map(lambda img: img.toFloat())\n",
    "    \n",
    "    # s2 = L8.merge(S2).mean()\n",
    "    s2 = S2.mean()\n",
    "\n",
    "    monthly_stack = s2.addBands(temp).addBands(preci)\n",
    "    if month is not None:\n",
    "        month_prefix = ee.String(month.lower() + \"_\")\n",
    "        renamed_bands = monthly_stack.bandNames().map(lambda b: month_prefix.cat(ee.String(b)))\n",
    "        monthly_stack = monthly_stack.rename(renamed_bands)\n",
    "    collection = ee.Image([monthly_stack, elevation, slope, aspect, twi, sand, clay, silt])\n",
    "    \n",
    "    return collection\n",
    "\n",
    "def fetch_indices_for_district(df, district, month, start_date, end_date):\n",
    "    global collections\n",
    "    \"\"\"Processes a district's data in batches and fetches satellite indices.\"\"\"\n",
    "    \n",
    "    # Filter district data\n",
    "    district_df = df[df[\"district\"] == district].reset_index(drop=True)\n",
    "    total_features = len(district_df)\n",
    "    \n",
    "    processed = 0\n",
    "    batch_number = 1\n",
    "    start_time = time.time()\n",
    "    all_results = []\n",
    "\n",
    "    while processed < total_features:\n",
    "        batch_df = district_df.iloc[processed : processed + BATCH_SIZE]\n",
    "        points = ee.FeatureCollection([\n",
    "            ee.Feature(ee.Geometry.Point(row['long'], row['lat']), {\n",
    "                'district' : row['district'],\n",
    "                'village' : row['village'],\n",
    "                'N': row['N'],\n",
    "                'P': row['P'],\n",
    "                'K': row['K'],\n",
    "                'B': row['B'],\n",
    "                'Fe': row['Fe'],\n",
    "                'Zn': row['Zn'],\n",
    "                'Cu': row['Cu'],\n",
    "                'S': row['S'],\n",
    "                'OC': row['OC'],\n",
    "                'pH': row['pH'],\n",
    "                'Mn': row['Mn'],\n",
    "                'EC': row['EC']\n",
    "            })\n",
    "            for _, row in batch_df.iterrows()\n",
    "        ])\n",
    "\n",
    "\n",
    "        points = points.filterBounds(state.geometry())\n",
    "        # Harmonized indices collection\n",
    "        roi = points.geometry().bounds()\n",
    "        # geemap.extract_values_to_points(points, collections, \"test.csv\")\n",
    "        collections = harmonize_collections(start_date, end_date, roi, month)\n",
    "        sampled_points = collections.sampleRegions(\n",
    "            collection=points, scale=30, tileScale=8, geometries=True\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            batch_data = sampled_points.getInfo()[\"features\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving batch {batch_number}: {e}\")\n",
    "            break\n",
    "\n",
    "        batch_results = [\n",
    "            {\n",
    "                \"longitude\": feature[\"geometry\"][\"coordinates\"][0],\n",
    "                \"latitude\": feature[\"geometry\"][\"coordinates\"][1],\n",
    "                **feature[\"properties\"]\n",
    "            }\n",
    "            for feature in batch_data\n",
    "        ]\n",
    "        all_results.extend(batch_results)\n",
    "\n",
    "        processed += BATCH_SIZE\n",
    "        batch_number += 1\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        remaining_batches = (total_features - processed) / BATCH_SIZE\n",
    "        estimated_time_remaining = elapsed_time / batch_number * remaining_batches\n",
    "        print(f\"Batch {batch_number-1} processed. {len(batch_results)} records fetched. Estimated Remaining: {estimated_time_remaining:.2f} sec\")\n",
    "\n",
    "    # Convert results to DataFrame and save\n",
    "    if all_results:\n",
    "        print(f\"Total records fetched : {len(all_results)} records\")\n",
    "        output_df = pd.DataFrame(all_results)\n",
    "        if month is None:\n",
    "            output_file = os.path.join(OUTPUT_FOLDER, f\"{district}_indices.csv\")\n",
    "        else:\n",
    "            output_file = os.path.join(OUTPUT_FOLDER, f\"{district}_{month.upper()}_indices.csv\")\n",
    "        output_df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea810cdb-45a1-4bb1-b1e6-018a94629d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import math\n",
    "# import geemap\n",
    "# import datetime\n",
    "\n",
    "# def renameBands(image):\n",
    "#     return image.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7'], ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "\n",
    "# def maskL8clouds(image):\n",
    "#     qa = image.select('QA_PIXEL')\n",
    "#     cloudMask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "#     shadowMask = qa.bitwiseAnd(1 << 3).eq(0)\n",
    "#     mask = cloudMask.And(shadowMask)\n",
    "#     scaled = image.multiply(0.0000275).add(-0.2)\n",
    "#     bands = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']\n",
    "#     return scaled.updateMask(mask).select(bands, ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']).toFloat()\n",
    "\n",
    "# def maskS2clouds(image):\n",
    "#     qa = image.select('QA60');\n",
    "#     # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "#     cloudBitMask = 1 << 10;\n",
    "#     cirrusBitMask = 1 << 11;\n",
    "#     mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "#     scaled = image.divide(10000)\n",
    "#     scaled = scaled.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'], ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "#     return scaled.updateMask(mask).toFloat()\n",
    "\n",
    "# # Apply harmonization for Sentinel-2\n",
    "# slopes = [1.0946, 1.0043, 1.0524, 0.8954, 1.0049, 1.0002]\n",
    "# intercepts = [-0.0107, 0.0026, -0.0015, 0.0033, 0.0065, 0.0046]\n",
    "\n",
    "# def convert(image):\n",
    "#   return image.select(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']).multiply(slopes).add(intercepts)\n",
    "\n",
    "# date_range_month = {\n",
    "#     \"Jan\" : (ee.Date(\"2023-01-01\"), ee.Date(\"2023-01-31\")),\n",
    "#     \"Feb\" : (ee.Date(\"2023-02-01\"), ee.Date(\"2023-02-28\")),\n",
    "#     \"Mar\" : (ee.Date(\"2023-03-01\"), ee.Date(\"2023-03-31\")),\n",
    "#     \"Apr\" : (ee.Date(\"2023-04-01\"), ee.Date(\"2023-04-30\")),\n",
    "#     \"May\" : (ee.Date(\"2023-05-01\"), ee.Date(\"2023-05-31\")),\n",
    "#     \"Jun\" : (ee.Date(\"2023-06-01\"), ee.Date(\"2023-06-30\")),\n",
    "#     \"Jul\" : (ee.Date(\"2023-07-01\"), ee.Date(\"2023-07-31\")),\n",
    "#     \"Aug\" : (ee.Date(\"2023-08-01\"), ee.Date(\"2023-08-31\")),\n",
    "#     \"Sep\" : (ee.Date(\"2023-09-01\"), ee.Date(\"2023-09-30\")),\n",
    "#     \"Oct\" : (ee.Date(\"2023-10-01\"), ee.Date(\"2023-10-31\")),\n",
    "#     \"Nov\" : (ee.Date(\"2023-11-01\"), ee.Date(\"2023-11-30\")),\n",
    "#     \"Dec\" : (ee.Date(\"2023-12-01\"), ee.Date(\"2023-12-31\"))\n",
    "# }\n",
    "\n",
    "# def harmonize_collections(roi):\n",
    "#     \"\"\"Fetches harmonized Sentinel-2 and Landsat collections with indices.\"\"\"\n",
    "\n",
    "#     def update(image):\n",
    "#       return image.multiply(0.002)\n",
    "\n",
    "#     monthly_images = []\n",
    "    \n",
    "#     elevation = ee.Image(\"USGS/SRTMGL1_003\").select(\"elevation\").clip(roi)\n",
    "#     slope = ee.Terrain.slope(elevation).rename('slope')\n",
    "#     aspect = ee.Terrain.aspect(elevation).rename('aspect')\n",
    "    \n",
    "#     slope_radians = slope.multiply(math.pi).divide(180)\n",
    "#     flow_accumulation = ee.Image(\"MERIT/Hydro/v1_0_1\").select(\"upa\").clip(roi) # Upstream Area (Flow Accumulation)\n",
    "    \n",
    "#     tan_slope = slope_radians.tan()\n",
    "#     safe_slope = tan_slope.where(tan_slope.eq(0), 0.001)\n",
    "#     twi = flow_accumulation.divide(safe_slope).log().rename('TWI')\n",
    "\n",
    "#     sand = ee.Image(\"projects/soilgrids-isric/sand_mean\").select([\"sand_0-5cm_mean\", \"sand_5-15cm_mean\"]).clip(roi).rename(['sand05', 'sand515']);\n",
    "#     silt = ee.Image(\"projects/soilgrids-isric/silt_mean\").select([\"silt_0-5cm_mean\", \"silt_5-15cm_mean\"]).clip(roi).rename(['silt05', 'silt515']);\n",
    "#     clay = ee.Image(\"projects/soilgrids-isric/clay_mean\").select([\"clay_0-5cm_mean\", \"clay_5-15cm_mean\"]).clip(roi).rename(['clay05', 'clay515']);\n",
    "\n",
    "#     L8_main = (\n",
    "#             ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
    "#             .filterBounds(roi)\n",
    "#             .filterDate(ee.Date(\"2023-01-01\"), ee.Date(\"2023-12-31\"))\n",
    "#     )\n",
    "\n",
    "#     S2_main = (\n",
    "#         ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "#         .filterBounds(roi)\n",
    "#         .filterDate(ee.Date(\"2023-01-01\"), ee.Date(\"2023-12-31\"))\n",
    "#     )\n",
    "    \n",
    "#     temp_main = (\n",
    "#             ee.ImageCollection(\"MODIS/061/MOD11A2\")\n",
    "#             .select('LST_Day_1km')\n",
    "#             .filterDate(ee.Date(\"2023-01-01\"), ee.Date(\"2023-12-31\"))\n",
    "#             .filterBounds(roi)\n",
    "#     )\n",
    "    \n",
    "#     preci_main = (\n",
    "#             ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\n",
    "#             .filterDate(ee.Date(\"2023-01-01\"), ee.Date(\"2023-12-31\"))\n",
    "#             .filterBounds(roi)      \n",
    "#     )\n",
    "#     band_names = []\n",
    "#     for month in date_range_month.keys():\n",
    "        \n",
    "#         start_date, end_date = date_range_month[month]\n",
    "        \n",
    "#         L8 = L8_main.filterDate(start_date, end_date).filter(ee.Filter.lt('CLOUD_COVER', 20)).map(maskL8clouds)\n",
    "#         S2 = S2_main.filterDate(start_date, end_date).filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)).map(maskS2clouds)\n",
    "#         temp = temp_main.filterDate(start_date, end_date).map(lambda img: update(img)).mean().rename('temp')\n",
    "#         preci = preci_main.filterDate(start_date, end_date).mean().rename('precipitation')\n",
    "\n",
    "#         # print(L8.first().bandNames().getInfo())\n",
    "#         # print(S2.first().bandNames().getInfo())\n",
    "#         # print(temp.bandNames().getInfo())\n",
    "#         # print(preci.bandNames().getInfo())\n",
    "        \n",
    "#         L8 = L8.map(convert)\n",
    "#         L8 = L8.map(lambda img: img.toFloat())\n",
    "#         S2 = S2.map(lambda img: img.toFloat())\n",
    "        \n",
    "#         s2 = L8.merge(S2).mean()\n",
    "\n",
    "#         # Stack and rename bands with month prefix\n",
    "#         monthly_stack = s2.addBands(temp).addBands(preci)\n",
    "#         # print(monthly_stack.bandNames().getInfo())\n",
    "#         month_prefix = ee.String(month.lower() + \"_\")\n",
    "#         renamed_bands = monthly_stack.bandNames().map(lambda b: month_prefix.cat(ee.String(b)))\n",
    "#         # band_names.extend(renamed_bands.getInfo())\n",
    "#         monthly_stack = monthly_stack.rename(renamed_bands)\n",
    "#         # print(monthly_stack.bandNames().getInfo())\n",
    "#         monthly_images.append(monthly_stack)\n",
    "        \n",
    "#     monthly_images.extend([elevation, slope, aspect, twi, sand, clay, silt])\n",
    "#     # band_names.extend(['elevation', 'slope', 'aspect', 'TWI', 'sand05', 'sand515', 'silt05', 'silt515', 'clay05', 'clay515'])\n",
    "#     # print(band_names)\n",
    "#     return ee.Image(monthly_images)\n",
    "\n",
    "# def fetch_indices_for_district(df, district):\n",
    "#     global collections\n",
    "#     \"\"\"Processes a district's data in batches and fetches satellite indices.\"\"\"\n",
    "    \n",
    "#     # Filter district data\n",
    "#     district_df = df[df[\"district\"] == district].reset_index(drop=True)\n",
    "#     total_features = len(district_df)\n",
    "    \n",
    "#     processed = 0\n",
    "#     batch_number = 1\n",
    "#     start_time = time.time()\n",
    "#     all_results = []\n",
    "\n",
    "#     while processed < total_features:\n",
    "#         batch_df = district_df.iloc[processed : processed + BATCH_SIZE]\n",
    "#         points = ee.FeatureCollection([\n",
    "#             ee.Feature(ee.Geometry.Point(row['long'], row['lat']), {\n",
    "#                 'district' : row['district'],\n",
    "#                 'village' : row['village'],\n",
    "#                 'date': row['date'],\n",
    "#                 'latitude': row['lat'],\n",
    "#                 'longitude': row['long'],\n",
    "#                 'N': row['N'],\n",
    "#                 'P': row['P'],\n",
    "#                 'K': row['K'],\n",
    "#                 'B': row['B'],\n",
    "#                 'Fe': row['Fe'],\n",
    "#                 'Zn': row['Zn'],\n",
    "#                 'Cu': row['Cu'],\n",
    "#                 'S': row['S'],\n",
    "#                 'OC': row['OC'],\n",
    "#                 'pH': row['pH'],\n",
    "#                 'Mn': row['Mn'],\n",
    "#                 'EC': row['EC']\n",
    "#             })\n",
    "#             for _, row in batch_df.iterrows()\n",
    "#         ])\n",
    "\n",
    "\n",
    "#         points = points.filterBounds(state.geometry())\n",
    "#         # Harmonized indices collection\n",
    "#         roi = points.geometry().bounds()\n",
    "#         collections = harmonize_collections(roi)\n",
    "        \n",
    "#         sampled_points = collections.sampleRegions(\n",
    "#             collection=points, scale=30, tileScale=8, geometries=False\n",
    "#         )\n",
    "\n",
    "#         try:\n",
    "#             batch_data = sampled_points.getInfo()[\"features\"]\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error retrieving batch {batch_number}: {e}\")\n",
    "#             break\n",
    "\n",
    "#         batch_results = [\n",
    "#             {\n",
    "#                 # \"longitude\": feature[\"geometry\"][\"coordinates\"][0],\n",
    "#                 # \"latitude\": feature[\"geometry\"][\"coordinates\"][1],\n",
    "#                 **feature[\"properties\"]\n",
    "#             }\n",
    "#             for feature in batch_data\n",
    "#         ]\n",
    "#         all_results.extend(batch_results)\n",
    "\n",
    "#         processed += BATCH_SIZE\n",
    "#         batch_number += 1\n",
    "\n",
    "#         elapsed_time = time.time() - start_time\n",
    "#         remaining_batches = (total_features - processed) / BATCH_SIZE\n",
    "#         estimated_time_remaining = elapsed_time / batch_number * remaining_batches\n",
    "#         print(f\"Batch {batch_number-1} processed. {len(batch_results)} records fetched. Estimated Remaining: {estimated_time_remaining:.2f} sec\")\n",
    "\n",
    "#     # Convert results to DataFrame and save\n",
    "#     if all_results:\n",
    "#         print(f\"Total records fetched : {len(all_results)} records\")\n",
    "#         output_df = pd.DataFrame(all_results)\n",
    "#         output_file = os.path.join(OUTPUT_FOLDER, f\"{district}_indices.csv\")\n",
    "#         output_df.to_csv(output_file, index=False)\n",
    "#         print(f\"Saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65879d66-d019-4251-a7a2-1c04f305ce4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def main():\n",
    "#     global collections\n",
    "#     \"\"\"Main function to process all districts.\"\"\"\n",
    "#     df = pd.read_csv(INPUT_CSV)\n",
    "    \n",
    "#     # Ensure necessary columns exist\n",
    "#     required_columns = {\"long\", \"lat\", \"district\", \"village\", \"date\"}\n",
    "#     if not required_columns.issubset(df.columns):\n",
    "#         raise ValueError(f\"CSV file must contain columns: {required_columns}\")\n",
    "\n",
    "#     # Process districts\n",
    "#     unique_districts = df[\"district\"].unique()\n",
    "#     print(f\"Total Districts: {len(unique_districts)}\")\n",
    "\n",
    "#     start_date, end_date = ee.Date(\"2023-01-01\"), ee.Date(\"2023-12-31\")\n",
    "    \n",
    "#     for district in unique_districts:\n",
    "#         # if district != \"BULANDSHAHR\":\n",
    "#         #     continue\n",
    "#         start_time = time.perf_counter()\n",
    "\n",
    "#         print(f\"\\nProcessing District: {district}\")\n",
    "#         batch_df = df[df[\"district\"] == district].reset_index(drop=True)\n",
    "#         total_features = len(batch_df)\n",
    "#         print(f\"Total Features in {district}: {total_features}\")\n",
    "\n",
    "#         # Annual mean data downloading\n",
    "#         if os.path.exists(os.path.join(OUTPUT_FOLDER, f\"{district}_indices.csv\")):\n",
    "#             print(f\"Features already extracted for {district} \")\n",
    "#             continue\n",
    "            \n",
    "#         fetch_indices_for_district(df, district, None, start_date, end_date)\n",
    "        \n",
    "#         # Month wise data donwloading \n",
    "#         # for month in date_range_month.keys():\n",
    "#         #     if os.path.exists(os.path.join(OUTPUT_FOLDER, f\"{district}_{month.upper()}_indices.csv\")):\n",
    "#         #         print(f\"Features already extracted for {district} for month {month.upper()}\")\n",
    "#         #         continue\n",
    "#         #     print(f\"\\nFetching data for month : {month.upper()}\")\n",
    "            \n",
    "#         #     start_date, end_date = date_range_month[month]\n",
    "#         #     fetch_indices_for_district(df, district, month, start_date, end_date)\n",
    "            \n",
    "#         end_time = time.perf_counter()\n",
    "#         elapsed_time = end_time - start_time\n",
    "#         a = datetime.timedelta(seconds=elapsed_time)\n",
    "#         print(\"Time taken : \" + str(a))\n",
    "        \n",
    "\n",
    "#     print(\"\\nAll districts processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9f6b51-96c4-436d-8725-e91b98e378f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import math\n",
    "\n",
    "CHECKPOINT_FILE = 'resume_checkpoint.json'\n",
    "SAVE_INTERVAL = 10  # Save every 10 batches\n",
    "\n",
    "def fetch_indices_for_aez(df, aez, month, start_date, end_date):\n",
    "    global collections\n",
    "\n",
    "    # Filter district data\n",
    "    district_df = df[(df['N'] >= 0) & (df['N'] <= 1000)]\n",
    "    total_features = len(district_df)\n",
    "    total_batches = math.ceil(total_features / (BATCH_SIZE * SAVE_INTERVAL))\n",
    "    print(f\"Total features in AEZ {aez} : {total_features}\")\n",
    "\n",
    "    # Load checkpoint if available\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, 'r') as f:\n",
    "            checkpoint = json.load(f)\n",
    "            processed = checkpoint.get('processed', 0)\n",
    "            file_counter = checkpoint.get('file_counter', 1)\n",
    "            print(f\"Resuming from checkpoint: processed={processed}, file_counter={file_counter}\")\n",
    "    else:\n",
    "        processed = 0\n",
    "        file_counter = 1\n",
    "\n",
    "    batch_number = processed // BATCH_SIZE + 1\n",
    "    start_time = time.time()\n",
    "    all_results = []\n",
    "\n",
    "    while processed < total_features:\n",
    "        batch_df = district_df.iloc[processed: processed + BATCH_SIZE]\n",
    "        points = ee.FeatureCollection([\n",
    "            ee.Feature(ee.Geometry.Point(row['long'], row['lat']), {\n",
    "                'district': row['district'],\n",
    "                'village': row['village'],\n",
    "                'N': row['N'],\n",
    "                'P': row['P'],\n",
    "                'K': row['K'],\n",
    "                'B': row['B'],\n",
    "                'Fe': row['Fe'],\n",
    "                'Zn': row['Zn'],\n",
    "                'Cu': row['Cu'],\n",
    "                'S': row['S'],\n",
    "                'OC': row['OC'],\n",
    "                'pH': row['pH'],\n",
    "                'Mn': row['Mn'],\n",
    "                'EC': row['EC']\n",
    "            })\n",
    "            for _, row in batch_df.iterrows()\n",
    "        ])\n",
    "\n",
    "        points = points.filterBounds(current_aez.geometry())\n",
    "        roi = points.geometry().bounds()\n",
    "        collections = harmonize_collections(start_date, end_date, roi, month)\n",
    "        sampled_points = collections.sampleRegions(\n",
    "            collection=points, scale=30, tileScale=8, geometries=True\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            batch_data = sampled_points.getInfo()[\"features\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving batch {batch_number}: {e}\")\n",
    "            break\n",
    "\n",
    "        batch_results = [\n",
    "            {\n",
    "                \"longitude\": feature[\"geometry\"][\"coordinates\"][0],\n",
    "                \"latitude\": feature[\"geometry\"][\"coordinates\"][1],\n",
    "                **feature[\"properties\"]\n",
    "            }\n",
    "            for feature in batch_data\n",
    "        ]\n",
    "        all_results.extend(batch_results)\n",
    "\n",
    "        # Save every SAVE_INTERVAL batches\n",
    "        if batch_number % SAVE_INTERVAL == 0:\n",
    "            output_df = pd.DataFrame(all_results)\n",
    "            output_file = os.path.join(\n",
    "                OUTPUT_FOLDER,\n",
    "                f\"AEZ_{aez}_batch{file_counter}_of_{total_batches}.csv\"\n",
    "            )\n",
    "            output_df.to_csv(output_file, index=False)\n",
    "            print(f\"Saved batch {file_counter}: {output_file}\")\n",
    "            all_results = []  # clear buffer\n",
    "\n",
    "            # Save checkpoint\n",
    "            checkpoint = {\n",
    "                'processed': processed + BATCH_SIZE,\n",
    "                'file_counter': file_counter + 1\n",
    "            }\n",
    "            with open(CHECKPOINT_FILE, 'w') as f:\n",
    "                json.dump(checkpoint, f)\n",
    "\n",
    "            file_counter += 1\n",
    "\n",
    "        processed += BATCH_SIZE\n",
    "        batch_number += 1\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        remaining_batches = (total_features - processed) / BATCH_SIZE\n",
    "        estimated_time_remaining = elapsed_time / batch_number * remaining_batches\n",
    "        print(f\"Batch {batch_number - 1} processed. {len(batch_results)} records fetched. Estimated Remaining: {estimated_time_remaining:.2f} sec\")\n",
    "\n",
    "    # Final save\n",
    "    if all_results:\n",
    "        output_df = pd.DataFrame(all_results)\n",
    "        output_file = os.path.join(\n",
    "            OUTPUT_FOLDER,\n",
    "            f\"AEZ_{aez}_batch{file_counter}_of_{total_batches}.csv\"\n",
    "        )\n",
    "        output_df.to_csv(output_file, index=False)\n",
    "        print(f\"Final save: {output_file}\")\n",
    "\n",
    "    # Cleanup checkpoint after full completion\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        os.remove(CHECKPOINT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19e532b2-aea4-45c3-bb56-3d7ba7f62f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    global collections\n",
    "    \"\"\"Main function to process all districts.\"\"\"\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    \n",
    "    # Ensure necessary columns exist\n",
    "    required_columns = {\"long\", \"lat\", \"district\", \"village\", \"date\"}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        raise ValueError(f\"CSV file must contain columns: {required_columns}\")\n",
    "\n",
    "    start_date, end_date = ee.Date(\"2023-01-01\"), ee.Date(\"2023-12-31\")\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    print(f\"\\nProcessing AEZ: {AEZ}\")\n",
    "    batch_df = df\n",
    "    total_features = len(batch_df)\n",
    "    print(f\"Total Features in {AEZ}: {total_features}\")\n",
    "\n",
    "    # Annual mean data downloading\n",
    "    if os.path.exists(os.path.join(OUTPUT_FOLDER, f\"AEZ_{AEZ}.csv\")):\n",
    "        print(f\"Features already extracted for {AEZ} \")\n",
    "        exit()\n",
    "    \n",
    "    fetch_indices_for_aez(df, AEZ, None, start_date, end_date)\n",
    "    \n",
    "    # Month wise data donwloading \n",
    "    # for month in date_range_month.keys():\n",
    "    #     if os.path.exists(os.path.join(OUTPUT_FOLDER, f\"{district}_{month.upper()}_indices.csv\")):\n",
    "    #         print(f\"Features already extracted for {district} for month {month.upper()}\")\n",
    "    #         continue\n",
    "    #     print(f\"\\nFetching data for month : {month.upper()}\")\n",
    "        \n",
    "    #     start_date, end_date = date_range_month[month]\n",
    "    #     fetch_indices_for_district(df, district, month, start_date, end_date)\n",
    "        \n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    a = datetime.timedelta(seconds=elapsed_time)\n",
    "    print(\"Time taken : \" + str(a))\n",
    "    \n",
    "\n",
    "    print(\"\\nAll data points processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f36fec-f35e-4375-a9f7-0afc88d093da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing AEZ: 5\n",
      "Total Features in 5: 201111\n",
      "Total features in AEZ 5 : 201000\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991ec5f-7d6c-4271-869e-0e9259f0af9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967cf616-ff2d-4564-b7ea-785a8b664f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
