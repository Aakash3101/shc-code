{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cac1a90-cbd7-465d-bc9d-45bcbd441f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Earth Engine initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ee\n",
    "import math\n",
    "import time\n",
    "import geemap\n",
    "import datetime \n",
    "import pandas as pd\n",
    "\n",
    "# ee.Authenticate()\n",
    "\n",
    "# Initialize Earth Engine\n",
    "try:\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "    print('Google Earth Engine initialized successfully!')\n",
    "except ee.EEException as e:\n",
    "    print('Google Earth Engine failed to initialize!', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f38919-e6ec-4a08-b794-37a854ddda18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANDAMAN & NICOBAR_AGRI_2023-24.csv',\n",
       " 'ANDHRA PRADESH_AGRI_2023-24.csv',\n",
       " 'ARUNACHAL PRADESH_AGRI_2023-24.csv',\n",
       " 'ASSAM_AGRI_2023-24.csv',\n",
       " 'BIHAR_AGRI_2023-24.csv',\n",
       " 'CHHATTISGARH_AGRI_2023-24.csv',\n",
       " 'GOA_AGRI_2023-24.csv',\n",
       " 'GUJARAT_AGRI_2023-24.csv',\n",
       " 'HARYANA_AGRI_2023-24.csv',\n",
       " 'HIMACHAL PRADESH_AGRI_2023-24.csv',\n",
       " 'JAMMU & KASHMIR_AGRI_2023-24.csv',\n",
       " 'JHARKHAND_AGRI_2023-24.csv',\n",
       " 'KARNATAKA_AGRI_2023-24.csv',\n",
       " 'LADAKH_AGRI_2023-24.csv',\n",
       " 'MADHYA PRADESH_AGRI_2023-24.csv',\n",
       " 'MAHARASHTRA_AGRI_2023-24.csv',\n",
       " 'MEGHALAYA_AGRI_2023-24.csv',\n",
       " 'MIZORAM_AGRI_2023-24.csv',\n",
       " 'NAGALAND_AGRI_2023-24.csv',\n",
       " 'ODISHA_AGRI_2023-24.csv',\n",
       " 'PUDUCHERRY_AGRI_2023-24.csv',\n",
       " 'PUNJAB_AGRI_2023-24.csv',\n",
       " 'RAJASTHAN_AGRI_2023-24.csv',\n",
       " 'SIKKIM_AGRI_2023-24.csv',\n",
       " 'TAMIL NADU_AGRI_2023-24.csv',\n",
       " 'TELANGANA_AGRI_2023-24.csv',\n",
       " 'TRIPURA_AGRI_2023-24.csv',\n",
       " 'UTTAR PRADESH_AGRI_2023-24.csv',\n",
       " 'UTTARAKHAND_AGRI_2023-24.csv',\n",
       " 'WEST BENGAL_AGRI_2023-24.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted(os.listdir(\"./shc_data/NORMALISED_DATA/2024\"))\n",
    "sorted(os.listdir(\"./shc_data/NORMALISED_DATA/AGRI_2023-24/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b546fb-253f-4979-975a-72805ab79ca3",
   "metadata": {},
   "source": [
    "## Please use the same names as listed below for the state variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63681f22-d3cf-4978-afd0-94f5917e78d0",
   "metadata": {},
   "source": [
    "0: \n",
    "Andaman & Nicobar\n",
    "1: \n",
    "Andhra Pradesh\n",
    "2: \n",
    "Arunachal Pradesh\n",
    "3: \n",
    "Assam\n",
    "4: \n",
    "Bihar\n",
    "5: \n",
    "Chandigarh\n",
    "6: \n",
    "Chhattishgarh\n",
    "7: \n",
    "Daman and Diu and Dadra and Nagar Haveli\n",
    "8: \n",
    "Delhi\n",
    "9: \n",
    "Goa\n",
    "10: \n",
    "Gujarat\n",
    "11: \n",
    "Haryana\n",
    "12: \n",
    "Himachal Pradesh\n",
    "13: \n",
    "Jammu and Kashmir\n",
    "14: \n",
    "Jharkhand\n",
    "15: \n",
    "Karnataka\n",
    "16: \n",
    "Kerala\n",
    "17: \n",
    "Ladakh\n",
    "18: \n",
    "Lakshadweep\n",
    "19: \n",
    "Madhya Pradesh\n",
    "20: \n",
    "Maharashtra\n",
    "21: \n",
    "Manipur\n",
    "22: \n",
    "Meghalaya\n",
    "23: \n",
    "Mizoram\n",
    "24: \n",
    "Nagaland\n",
    "25: \n",
    "Odisha\n",
    "26: \n",
    "Puducherry\n",
    "27: \n",
    "Puducherry\n",
    "28: \n",
    "Punjab\n",
    "29: \n",
    "Rajasthan\n",
    "30: \n",
    "Sikkim\n",
    "31: \n",
    "Tamilnadu\n",
    "32: \n",
    "Telengana\n",
    "33: \n",
    "Tripura\n",
    "34: \n",
    "Uttar Pradesh\n",
    "35: \n",
    "Uttarakhand\n",
    "36: \n",
    "West Bengal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6dbe2a-3c66-4047-b175-a9e1899ec8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === CONFIGURABLE PARAMETERS ===\n",
    "DATA_DIR = \"./shc_data/NORMALISED_DATA/AGRI_2023-24/\"\n",
    "INPUT_CSV = os.path.join(DATA_DIR, \"WEST BENGAL_AGRI_2023-24.csv\")  # CSV containing soil properties\n",
    "BATCH_SIZE = 3000  # Number of points processed per batch\n",
    "\n",
    "india_districts = ee.FeatureCollection(\"projects/ee-aakash312000/assets/state\")\n",
    "state = india_districts.filter(ee.Filter.eq('State_Name', 'West Bengal'))\n",
    "\n",
    "# Initialize start date and end date\n",
    "SD = pd.to_datetime(\"2023-07-01\")\n",
    "ED = pd.to_datetime(\"2024-06-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e943095-3cd8-4630-a946-ebf5f0194c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60');\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10;\n",
    "    cirrusBitMask = 1 << 11;\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "    scaled = image.divide(10000)\n",
    "    scaled = scaled.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'], ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "    return scaled.updateMask(mask).toFloat()\n",
    "\n",
    "\n",
    "def fetch_satellite_data(start_date, end_date, roi):\n",
    "    \"\"\"Fetches Physical properties and Sentinel-2 bands\"\"\"\n",
    "\n",
    "    def update(image):\n",
    "      return image.multiply(0.002)\n",
    "\n",
    "    S2 = (\n",
    "        ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "        .filterBounds(roi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 40))\n",
    "        .map(maskS2clouds)\n",
    "    )\n",
    "    \n",
    "    temp = (\n",
    "            ee.ImageCollection(\"MODIS/061/MOD11A2\")\n",
    "            .select('LST_Day_1km')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterBounds(roi)\n",
    "            .map(lambda img: update(img))\n",
    "            .mean()\n",
    "            .rename('temp')\n",
    "    )\n",
    "    \n",
    "    preci = (\n",
    "            ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\n",
    "            .filterDate(start_date, end_date)\n",
    "            .filterBounds(roi)\n",
    "            .mean()\n",
    "            .rename('precipitation')      \n",
    "    )\n",
    "\n",
    "    elevation = ee.Image(\"USGS/SRTMGL1_003\").select(\"elevation\").clip(roi)\n",
    "    slope = ee.Terrain.slope(elevation).rename('slope')\n",
    "    aspect = ee.Terrain.aspect(elevation).rename('aspect')\n",
    "    \n",
    "    slope_radians = slope.multiply(math.pi).divide(180)\n",
    "    \n",
    "    flow_accumulation = ee.Image(\"MERIT/Hydro/v1_0_1\").select(\"upa\").clip(roi) # Upstream Area (Flow Accumulation)\n",
    "    \n",
    "    tan_slope = slope_radians.tan()\n",
    "    safe_slope = tan_slope.where(tan_slope.eq(0), 0.001)\n",
    "    \n",
    "    twi = flow_accumulation.divide(safe_slope).log().rename('TWI')\n",
    "\n",
    "    sand = ee.Image(\"projects/soilgrids-isric/sand_mean\").select([\"sand_0-5cm_mean\", \"sand_5-15cm_mean\"]).clip(roi).rename(['sand05', 'sand515']);\n",
    "    silt = ee.Image(\"projects/soilgrids-isric/silt_mean\").select([\"silt_0-5cm_mean\", \"silt_5-15cm_mean\"]).clip(roi).rename(['silt05', 'silt515']);\n",
    "    clay = ee.Image(\"projects/soilgrids-isric/clay_mean\").select([\"clay_0-5cm_mean\", \"clay_5-15cm_mean\"]).clip(roi).rename(['clay05', 'clay515']);\n",
    "\n",
    "    S2 = S2.map(lambda img: img.toFloat())\n",
    "    s2 = S2.mean()\n",
    "\n",
    "    collection = ee.Image([s2, temp, preci, elevation, slope, aspect, twi, sand, clay, silt])\n",
    "    \n",
    "    return collection\n",
    "\n",
    "\n",
    "def fetch_indices_for_district(df, district, month, start_date, end_date):\n",
    "    \"\"\"Processes a district's data in batches and fetches satellite indices.\"\"\"\n",
    "    \n",
    "    # Filter district data\n",
    "    district_df = df[df[\"district\"] == district].reset_index(drop=True)\n",
    "    total_features = len(district_df)\n",
    "    \n",
    "    processed = 0\n",
    "    batch_number = 1\n",
    "\n",
    "    while processed < total_features:\n",
    "        batch_df = district_df.iloc[processed : processed + BATCH_SIZE]\n",
    "        valid_points = []\n",
    "        # loop through the district dataframe batch\n",
    "        for _, row in batch_df.iterrows():\n",
    "            # sanity check if survey data lies between start and end date\n",
    "            if (pd.to_datetime(row['date']) >= SD and pd.to_datetime(row['date']) <= ED):\n",
    "                valid_points.append(\n",
    "                    ee.Feature(ee.Geometry.Point(row['long'], row['lat']), {\n",
    "                        'district' : row['district'],\n",
    "                        'village' : row['village'],\n",
    "                        'date': row['date'],\n",
    "                        'start_date': SD,\n",
    "                        'end_date': ED,\n",
    "                        'N': row['N'],\n",
    "                        'P': row['P'],\n",
    "                        'K': row['K'],\n",
    "                        'B': row['B'],\n",
    "                        'Fe': row['Fe'],\n",
    "                        'Zn': row['Zn'],\n",
    "                        'Cu': row['Cu'],\n",
    "                        'S': row['S'],\n",
    "                        'OC': row['OC'],\n",
    "                        'pH': row['pH'],\n",
    "                        'Mn': row['Mn'],\n",
    "                        'EC': row['EC']}))\n",
    "\n",
    "        points = ee.FeatureCollection(valid_points) \n",
    "        points = points.filterBounds(state.geometry())\n",
    "        roi = points.geometry().bounds()\n",
    "        collections = fetch_satellite_data(start_date, end_date, roi)\n",
    "        sampled_points = collections.sampleRegions(\n",
    "            collection=points, scale=30, tileScale=8, geometries=True\n",
    "        )\n",
    "\n",
    "        state_name = INPUT_CSV.split(\"/\")[-1].split(\".csv\")[0].replace(\" \", \"_\").replace(\"&\", \"_\")\n",
    "\n",
    "        # Export the CSV file to google drive\n",
    "        task = ee.batch.Export.table.toDrive(\n",
    "            collection=sampled_points,\n",
    "            description=f\"{state_name}_sampled_batch_{batch_number}\",\n",
    "            folder='GEE_Exports_Aakash',\n",
    "            fileNamePrefix=f\"{state_name}_{district}_batch{batch_number}\",\n",
    "            fileFormat='CSV'\n",
    "        )\n",
    "        task.start()\n",
    "\n",
    "        processed += BATCH_SIZE\n",
    "        batch_number += 1\n",
    "        print(f\"Batch {batch_number-1} processed. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65879d66-d019-4251-a7a2-1c04f305ce4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to process all districts.\"\"\"\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    \n",
    "    # Ensure necessary columns exist\n",
    "    required_columns = {\"long\", \"lat\", \"district\", \"village\", \"date\"}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        raise ValueError(f\"CSV file must contain columns: {required_columns}\")\n",
    "\n",
    "    # Process districts\n",
    "    unique_districts = df[\"district\"].unique()\n",
    "    print(f\"Total Districts: {len(unique_districts)}\")\n",
    "\n",
    "    start_date, end_date = ee.Date(SD), ee.Date(ED)\n",
    "    \n",
    "    for district in unique_districts:\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        print(f\"\\nProcessing District: {district}\")\n",
    "        batch_df = df[df[\"district\"] == district].reset_index(drop=True)\n",
    "        total_features = len(batch_df)\n",
    "        print(f\"Total Features in {district}: {total_features}\")\n",
    "            \n",
    "        fetch_indices_for_district(df, district, None, start_date, end_date)\n",
    "            \n",
    "        end_time = time.perf_counter()\n",
    "        elapsed_time = end_time - start_time\n",
    "        a = datetime.timedelta(seconds=elapsed_time)\n",
    "        print(\"Time taken : \" + str(a))\n",
    "        \n",
    "    print(\"\\nAll districts processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f36fec-f35e-4375-a9f7-0afc88d093da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Districts: 22\n",
      "\n",
      "Processing District: 24 PARAGANAS NORTH\n",
      "Total Features in 24 PARAGANAS NORTH: 8574\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Time taken : 0:00:57.116135\n",
      "\n",
      "Processing District: 24 PARAGANAS SOUTH\n",
      "Total Features in 24 PARAGANAS SOUTH: 13340\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Batch 4 processed. \n",
      "Batch 5 processed. \n",
      "Time taken : 0:01:31.794129\n",
      "\n",
      "Processing District: ALIPURDUAR\n",
      "Total Features in ALIPURDUAR: 4298\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Time taken : 0:00:28.690450\n",
      "\n",
      "Processing District: BANKURA\n",
      "Total Features in BANKURA: 10713\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Batch 4 processed. \n",
      "Time taken : 0:01:13.782102\n",
      "\n",
      "Processing District: BIRBHUM\n",
      "Total Features in BIRBHUM: 15061\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Batch 4 processed. \n",
      "Batch 5 processed. \n",
      "Batch 6 processed. \n",
      "Time taken : 0:01:40.810254\n",
      "\n",
      "Processing District: COOCHBEHAR\n",
      "Total Features in COOCHBEHAR: 7364\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Time taken : 0:00:49.230325\n",
      "\n",
      "Processing District: DARJEELING\n",
      "Total Features in DARJEELING: 2325\n",
      "Batch 1 processed. \n",
      "Time taken : 0:00:15.978107\n",
      "\n",
      "Processing District: DINAJPUR DAKSHIN\n",
      "Total Features in DINAJPUR DAKSHIN: 5553\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Time taken : 0:00:44.102403\n",
      "\n",
      "Processing District: DINAJPUR UTTAR\n",
      "Total Features in DINAJPUR UTTAR: 8233\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Time taken : 0:00:55.148697\n",
      "\n",
      "Processing District: HOOGHLY\n",
      "Total Features in HOOGHLY: 19786\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Batch 4 processed. \n",
      "Batch 5 processed. \n",
      "Batch 6 processed. \n",
      "Batch 7 processed. \n",
      "Time taken : 0:02:22.081085\n",
      "\n",
      "Processing District: HOWRAH\n",
      "Total Features in HOWRAH: 2747\n",
      "Batch 1 processed. \n",
      "Time taken : 0:00:18.141138\n",
      "\n",
      "Processing District: JALPAIGURI\n",
      "Total Features in JALPAIGURI: 4034\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Time taken : 0:00:27.286395\n",
      "\n",
      "Processing District: JHARGRAM\n",
      "Total Features in JHARGRAM: 988\n",
      "Batch 1 processed. \n",
      "Time taken : 0:00:06.962756\n",
      "\n",
      "Processing District: KALIMPONG\n",
      "Total Features in KALIMPONG: 1836\n",
      "Batch 1 processed. \n",
      "Time taken : 0:00:12.031701\n",
      "\n",
      "Processing District: MALDAH\n",
      "Total Features in MALDAH: 8430\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Time taken : 0:00:54.507544\n",
      "\n",
      "Processing District: MEDINIPUR EAST\n",
      "Total Features in MEDINIPUR EAST: 12629\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Batch 4 processed. \n",
      "Batch 5 processed. \n",
      "Time taken : 0:01:25.558784\n",
      "\n",
      "Processing District: MEDINIPUR WEST\n",
      "Total Features in MEDINIPUR WEST: 8048\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Time taken : 0:00:54.141007\n",
      "\n",
      "Processing District: MURSHIDABAD\n",
      "Total Features in MURSHIDABAD: 16472\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Batch 4 processed. \n",
      "Batch 5 processed. \n",
      "Batch 6 processed. \n",
      "Time taken : 0:01:50.499223\n",
      "\n",
      "Processing District: NADIA\n",
      "Total Features in NADIA: 9644\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Batch 4 processed. \n",
      "Time taken : 0:01:05.723634\n",
      "\n",
      "Processing District: PASCHIM BARDHAMAN\n",
      "Total Features in PASCHIM BARDHAMAN: 3235\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Time taken : 0:00:21.613819\n",
      "\n",
      "Processing District: PURBA BARDHAMAN\n",
      "Total Features in PURBA BARDHAMAN: 13538\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Batch 4 processed. \n",
      "Batch 5 processed. \n",
      "Time taken : 0:01:32.223701\n",
      "\n",
      "Processing District: PURULIA\n",
      "Total Features in PURULIA: 7915\n",
      "Batch 1 processed. \n",
      "Batch 2 processed. \n",
      "Batch 3 processed. \n",
      "Time taken : 0:00:52.417520\n",
      "\n",
      "All districts processed successfully!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca26cca-e7d0-403d-9092-346930fcdf45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
